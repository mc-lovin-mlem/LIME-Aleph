{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME-Aleph\n",
    "\n",
    "### KI-Campus Aufgabe\n",
    "\n",
    "Willkommen zum Arbeitsauftrag für das Modul __LIME-Aleph__ im KI-Campus. Hier werden Sie den typischen Ablauf zum Finden einer symbolischen Erklärung für Black-Box Netzwerke mithilfe der LIME-Aleph Bibliothek Stück für Stück erarbeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py @ file:///C:/ci/absl-py_1603893176799/work\n",
      "aiohttp @ file:///C:/ci/aiohttp_1602530358780/work\n",
      "appdirs @ file:///home/conda/feedstock_root/build_artifacts/appdirs_1603108395799/work\n",
      "argon2-cffi @ file:///C:/ci/argon2-cffi_1596828549974/work\n",
      "astor==0.8.1\n",
      "async-generator==1.10\n",
      "async-timeout==3.0.1\n",
      "attrs @ file:///tmp/build/80754af9/attrs_1604765588209/work\n",
      "backcall==0.2.0\n",
      "bleach @ file:///tmp/build/80754af9/bleach_1600439572647/work\n",
      "blinker==1.4\n",
      "brotlipy==0.7.0\n",
      "cachetools @ file:///tmp/build/80754af9/cachetools_1596822027882/work\n",
      "certifi==2020.12.5\n",
      "cffi @ file:///C:/ci/cffi_1605538148575/work\n",
      "chardet @ file:///C:/ci/chardet_1605303259695/work\n",
      "click==7.1.2\n",
      "cloudpickle @ file:///tmp/build/80754af9/cloudpickle_1598884132938/work\n",
      "colorama @ file:///tmp/build/80754af9/colorama_1603211150991/work\n",
      "cryptography @ file:///C:/ci/cryptography_1605544557248/work\n",
      "cycler==0.10.0\n",
      "cytoolz==0.11.0\n",
      "dask @ file:///tmp/build/80754af9/dask-core_1602083700509/work\n",
      "decorator==4.4.2\n",
      "defusedxml==0.6.0\n",
      "entrypoints==0.3\n",
      "gast==0.2.2\n",
      "google-auth @ file:///tmp/build/80754af9/google-auth_1604100403705/work\n",
      "google-auth-oauthlib @ file:///tmp/build/80754af9/google-auth-oauthlib_1603929124518/work\n",
      "google-pasta==0.2.0\n",
      "grpcio @ file:///C:/ci/grpcio_1597406403308/work\n",
      "h5py==2.10.0\n",
      "idna @ file:///tmp/build/80754af9/idna_1593446292537/work\n",
      "imageio @ file:///tmp/build/80754af9/imageio_1594161405741/work\n",
      "importlib-metadata @ file:///tmp/build/80754af9/importlib-metadata_1602276842396/work\n",
      "ipykernel @ file:///C:/ci/ipykernel_1596208728219/work/dist/ipykernel-5.3.4-py3-none-any.whl\n",
      "Note: you may need to restart the kernel to use updated packages.ipython @ file:///C:/ci/ipython_1604101327119/work\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.5.1\n",
      "jedi @ file:///C:/ci/jedi_1596472767194/work\n",
      "Jinja2==2.11.2\n",
      "joblib @ file:///tmp/build/80754af9/joblib_1601912903842/work\n",
      "jsonschema @ file:///tmp/build/80754af9/jsonschema_1602607155483/work\n",
      "jupyter-client @ file:///tmp/build/80754af9/jupyter_client_1601311786391/work\n",
      "jupyter-core==4.6.3\n",
      "jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work\n",
      "Keras==2.3.1\n",
      "Keras-Applications @ file:///tmp/build/80754af9/keras-applications_1594366238411/work\n",
      "Keras-Preprocessing==1.1.0\n",
      "kiwisolver @ file:///C:/ci/kiwisolver_1603996595157/work\n",
      "lime==0.2.0.1\n",
      "Markdown @ file:///C:/ci/markdown_1605111187600/work\n",
      "MarkupSafe @ file:///C:/ci/markupsafe_1594405949945/work\n",
      "matplotlib @ file:///C:/ci/matplotlib-base_1603356257853/work\n",
      "mistune @ file:///C:/ci/mistune_1594373272338/work\n",
      "mkl-fft==1.2.0\n",
      "mkl-random==1.1.1\n",
      "mkl-service==2.3.0\n",
      "multidict @ file:///C:/ci/multidict_1600456486794/work\n",
      "nbclient @ file:///tmp/build/80754af9/nbclient_1602783176460/work\n",
      "nbconvert @ file:///C:/ci/nbconvert_1601914921407/work\n",
      "nbformat @ file:///tmp/build/80754af9/nbformat_1602783287752/work\n",
      "nest-asyncio @ file:///tmp/build/80754af9/nest-asyncio_1605115881283/work\n",
      "\n",
      "networkx @ file:///tmp/build/80754af9/networkx_1598376031484/work\n",
      "notebook @ file:///C:/ci/notebook_1601494955742/work\n",
      "numpy @ file:///C:/ci/numpy_and_numpy_base_1603468620949/work\n",
      "oauthlib==3.1.0\n",
      "olefile==0.46\n",
      "opt-einsum==3.1.0\n",
      "packaging==20.4\n",
      "pandocfilters @ file:///C:/ci/pandocfilters_1605102427207/work\n",
      "parso==0.7.0\n",
      "pickleshare @ file:///C:/ci/pickleshare_1594374056827/work\n",
      "Pillow @ file:///C:/ci/pillow_1603821929285/work\n",
      "pooch @ file:///home/conda/feedstock_root/build_artifacts/pooch_1606467285986/work\n",
      "prometheus-client==0.8.0\n",
      "prompt-toolkit @ file:///tmp/build/80754af9/prompt-toolkit_1602688806899/work\n",
      "protobuf==3.13.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycparser @ file:///tmp/build/80754af9/pycparser_1594388511720/work\n",
      "Pygments @ file:///tmp/build/80754af9/pygments_1604103097372/work\n",
      "PyJWT==1.7.1\n",
      "pyOpenSSL @ file:///tmp/build/80754af9/pyopenssl_1605545627475/work\n",
      "pyparsing==2.4.7\n",
      "pyreadline==2.1\n",
      "pyrsistent @ file:///C:/ci/pyrsistent_1600123688363/work\n",
      "PySocks @ file:///C:/ci/pysocks_1594394709107/work\n",
      "pyswip==0.2.10\n",
      "python-dateutil==2.8.1\n",
      "PyWavelets @ file:///C:/ci/pywavelets_1601658407053/work\n",
      "pywin32==227\n",
      "pywinpty==0.5.7\n",
      "PyYAML==5.3.1\n",
      "pyzmq==19.0.2\n",
      "requests @ file:///tmp/build/80754af9/requests_1592841827918/work\n",
      "requests-oauthlib==1.3.0\n",
      "rsa @ file:///tmp/build/80754af9/rsa_1596998415516/work\n",
      "scikit-image==0.18.1\n",
      "scikit-learn @ file:///C:/ci/scikit-learn_1598376983131/work\n",
      "scipy @ file:///C:/ci/scipy_1597686737426/work\n",
      "Send2Trash==1.5.0\n",
      "six @ file:///C:/ci/six_1605205426665/work\n",
      "tensorboard @ file:///home/builder/ktietz/conda/conda-bld/tensorboard_1604313476433/work/tmp_pip_dir\n",
      "tensorboard-plugin-wit==1.6.0\n",
      "tensorflow==2.1.0\n",
      "tensorflow-estimator==2.1.0\n",
      "termcolor==1.1.0\n",
      "terminado==0.9.1\n",
      "testpath==0.4.4\n",
      "threadpoolctl @ file:///tmp/tmp9twdgx9k/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "tifffile==2020.10.1\n",
      "toolz @ file:///tmp/build/80754af9/toolz_1601054250827/work\n",
      "tornado==6.0.4\n",
      "tqdm==4.52.0\n",
      "traitlets @ file:///tmp/build/80754af9/traitlets_1602787416690/work\n",
      "urllib3 @ file:///tmp/build/80754af9/urllib3_1603305693037/work\n",
      "wcwidth @ file:///tmp/build/80754af9/wcwidth_1593447189090/work\n",
      "webcolors==1.11.1\n",
      "webencodings==0.5.1\n",
      "Werkzeug==0.16.1\n",
      "widgetsnbextension==3.5.1\n",
      "win-inet-pton @ file:///C:/ci/win_inet_pton_1605306165655/work\n",
      "wincertstore==0.2\n",
      "wrapt==1.12.1\n",
      "yarl @ file:///C:/ci/yarl_1602679793616/work\n",
      "zipp @ file:///tmp/build/80754af9/zipp_1604001098328/work\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen zunächst mal die nötigen Bibliotheken importieren und einige nutzerdefinierbare Parameter erzeugen. Eine zu klassifizierende Bilddatei sowie ein vortrainiertes Modell sind schon vorhanden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "from skimage.util import img_as_float32\n",
    "from skimage.transform import resize\n",
    "from scripts.train_model import own_rel\n",
    "#from scripts import own_rel\n",
    "from skimage import io\n",
    "from skimage.io import imshow, show, imsave\n",
    "import shutil\n",
    "\n",
    "import lime_aleph.lime_aleph as la\n",
    "\n",
    "#NOTEBOOK_PATH = \"notebooks/\" #\n",
    "IMAGE_FILE = \"pos9000.png\" # The path to the image file to be classified by the black-box\n",
    "MODEL = \"../models_to_explain/model_tower.h5\" # The path to the pre-trained model\n",
    "K = 3 # The number of important superpixels to be used for perturbation\n",
    "N = 1000 # The sample size for LIME\n",
    "OUTPUT_DIR = \"../output/\" # A path for a directory to save intermediate and output data\n",
    "T = 0.8 # The threshold for the binary classifier for when an example is classified as 'positive'\n",
    "NOISE = 10 # The allowed false-positive rate for Aleph in percent.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sollte es noch temporäre Daten aus früheren Durchläufen geben, sollen diese nun gelöscht werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wollen wir das Bild und das vortrainierte Modell in den Speicher laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = img_as_float32(io.imread(IMAGE_FILE))\n",
    "image = resize(image, (own_rel.IMAGE_SIZE, own_rel.IMAGE_SIZE), anti_aliasing=True)\n",
    "\n",
    "model = own_rel.own_rel()\n",
    "model.load_weights(MODEL)\n",
    "\n",
    "io.imshow(image)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der nächste Schritt soll nun sein, die im Bild vorhandenen Elemente automatisch zu annotieren. Benutzen Sie hierfür die Funktion __annotate_image_parts__ aus dem bereits importierten __lime_aleph__ package mit den benötigten Parametern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LIME...\n",
      "True class of the image is:  1\n",
      "Negative estimator: 0.023822417\n",
      "Positive estimator: 0.9761776\n",
      "Starting the explanation generation process. This may take several minutes. Seriously. Grab a cup of coffee.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9ea02c744d41a2bba69900e9148713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intercept -0.17393427155500035\n",
      "Prediction_local [0.27813974]\n",
      "Right: 0.023822423\n",
      "Intercept 1.1739342743028347\n",
      "Prediction_local [0.72186026]\n",
      "Right: 0.9761776\n",
      "Elapsed time: 2.5285263061523438\n",
      "Number of superpixels: 64\n",
      "Annotating the superpixels...\n",
      "Weight of sp:  44 is:  0.1219462987606652\n",
      "Weight of sp:  52 is:  0.1124074378466645\n",
      "Weight of sp:  60 is:  0.1016981970756643\n",
      "Weight of sp:  36 is:  -0.042374532063209944\n",
      "Weight of sp:  27 is:  -0.04052891041531704\n",
      "Weight of sp:  41 is:  -0.03832481874307669\n",
      "Weight of sp:  39 is:  -0.03338210402771914\n",
      "Weight of sp:  46 is:  -0.032735714056669016\n",
      "Weight of sp:  30 is:  -0.03202343572437506\n",
      "Weight of sp:  15 is:  -0.029162045284843677\n",
      "Weight of sp:  38 is:  -0.029002108514277092\n",
      "Weight of sp:  45 is:  -0.02693699261939816\n",
      "Weight of sp:  33 is:  -0.02668297272440068\n",
      "Weight of sp:  56 is:  0.02600993457163372\n",
      "Weight of sp:  26 is:  -0.025652542394090202\n",
      "Weight of sp:  58 is:  -0.025521825542651054\n",
      "Weight of sp:  22 is:  -0.025337253222054924\n",
      "Weight of sp:  61 is:  -0.024531660284573424\n",
      "Weight of sp:  59 is:  -0.02252684189388316\n",
      "Weight of sp:  50 is:  -0.02191650160363162\n",
      "Weight of sp:  25 is:  -0.02152729182642702\n",
      "Weight of sp:  14 is:  -0.020875780282603534\n",
      "Weight of sp:  8 is:  -0.020637749464263153\n",
      "Weight of sp:  4 is:  -0.020533410404232403\n",
      "Weight of sp:  12 is:  -0.020218764829584786\n",
      "Weight of sp:  21 is:  -0.017438793555012683\n",
      "Weight of sp:  29 is:  -0.017086675076206783\n",
      "Weight of sp:  51 is:  -0.015643990992208\n",
      "Weight of sp:  20 is:  -0.01542050573850561\n",
      "Weight of sp:  28 is:  -0.01427304058493183\n",
      "Weight of sp:  43 is:  -0.014243550137897616\n",
      "Weight of sp:  23 is:  -0.014093045325165919\n",
      "Weight of sp:  54 is:  -0.013361808466062983\n",
      "Weight of sp:  62 is:  -0.013188390540297395\n",
      "Weight of sp:  53 is:  -0.011865950124053889\n",
      "Weight of sp:  47 is:  -0.011504735537481584\n",
      "Weight of sp:  18 is:  0.010930270184601281\n",
      "Weight of sp:  3 is:  -0.010659883012906959\n",
      "Weight of sp:  34 is:  -0.0104896370003193\n",
      "Weight of sp:  31 is:  -0.010242318736046287\n",
      "Weight of sp:  2 is:  -0.0099401049988558\n",
      "Weight of sp:  11 is:  -0.009920393925421243\n",
      "Weight of sp:  19 is:  -0.009849512744241335\n",
      "Weight of sp:  55 is:  -0.009686555822285904\n",
      "Weight of sp:  63 is:  -0.009625069901448685\n",
      "Weight of sp:  13 is:  -0.0078585310289419\n",
      "Weight of sp:  5 is:  0.0075734613082152485\n",
      "Weight of sp:  16 is:  0.007087689913627967\n",
      "Weight of sp:  1 is:  0.006672912929170039\n",
      "Weight of sp:  24 is:  -0.006255902501495315\n",
      "Weight of sp:  32 is:  -0.005465457995121333\n",
      "Weight of sp:  7 is:  -0.0040630192681582475\n",
      "Weight of sp:  40 is:  -0.0038944069930284928\n",
      "Weight of sp:  6 is:  0.0038818761107845203\n",
      "Weight of sp:  17 is:  -0.0034302081935286086\n",
      "Weight of sp:  9 is:  -0.003312796140990332\n",
      "Weight of sp:  49 is:  0.0029454991347027293\n",
      "Weight of sp:  10 is:  0.0023260194892292096\n",
      "Weight of sp:  35 is:  -0.0022281470856189496\n",
      "Weight of sp:  37 is:  0.002034412372764718\n",
      "Weight of sp:  48 is:  -0.0016271325339337948\n",
      "Weight of sp:  57 is:  0.0015355370985753413\n",
      "Weight of sp:  0 is:  -0.0010678890971786935\n",
      "Weight of sp:  42 is:  -0.0009528537291932709\n"
     ]
    }
   ],
   "source": [
    "#[SOLUTION]\n",
    "\n",
    "annotated_image = la.annotate_image_parts(image, model, OUTPUT_DIR, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do it manually....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LIME...\n",
      "Negative estimator: 0.023822417\n",
      "Positive estimator: 0.9761776\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Running LIME...\")\n",
    "\n",
    "true_class = -1\n",
    "predictions = model.predict_proba(np.array([image])) #Probabilities\n",
    "predictions = np.squeeze(predictions) #to get rid of the third dimension\n",
    "true_class = np.argmax(predictions)\n",
    "\n",
    "# the softmax output for the two classes:\n",
    "print(\"Negative estimator:\", predictions[0])\n",
    "print(\"Positive estimator:\", predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the explanation generation process. This may take several minutes. Seriously. Grab a cup of coffee.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b224b1dc78746059a1f0905b691452d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intercept -0.21171518475171316\n",
      "Prediction_local [0.31240813]\n",
      "Right: 0.023822423\n",
      "Intercept 1.2117151791536478\n",
      "Prediction_local [0.68759188]\n",
      "Right: 0.9761776\n",
      "Elapsed time: 2.5556674003601074\n"
     ]
    }
   ],
   "source": [
    "annotated_image = la.Image()\n",
    "annotated_image.true_class = true_class\n",
    "\n",
    "annotated_image.original_image = image\n",
    "\n",
    "\n",
    "from lime import lime_image\n",
    "from sources.own_segmentation.scikit_image import SegmentationAlgorithm\n",
    "import time\n",
    "\n",
    "n_lime_samples=1000\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer(verbose=True)\n",
    "print('Starting the explanation generation process. This may take several minutes. Seriously. Grab a cup of coffee.')\n",
    "sf = SegmentationAlgorithm('quadratic', n_quads=8) # our own segmentation algorithm. A uniform grid.\n",
    "tmp = time.time()\n",
    "explanation = explainer.explain_instance(image, model.predict_proba, segmentation_fn=sf, top_labels=2, num_samples=n_lime_samples, hide_color=0)\n",
    "print(\"Elapsed time: \" + str(time.time() - tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x192f0ceb0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "\n",
    "temp, mask = annotated_image.explanation.get_image_and_mask(true_class, positive_only=True, num_features=3, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x192f9e730>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp, mask = explanation.get_image_and_mask(0, positive_only=True, num_features=3, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem das Bild nun annotiert ist (als Annotation wurden auch die Gewichte von LIME für die einzelnen Elemente gefunden), können wir nun die wichtigsten __K__ Bildelemente mit der Funktion __find_important_parts__ finden. Anschließend können Sie auch die Relationen zwischen den Bildteilen mit der Funktion __find_spatial_relations__ finden lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'superpixels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0f553fade217>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#[SOLUTION]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimportant_superpixels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_important_parts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotated_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mrelations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_spatial_relations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportant_superpixels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\corona_quarantaene\\KI_Campus\\git\\LIME-Aleph\\lime_aleph\\lime_aleph.py\u001b[0m in \u001b[0;36mfind_important_parts\u001b[1;34m(annotated_image, k)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;31m# find the important superpixels according to the user-given parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0msps_sorted_by_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotated_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuperpixels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlime_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlime_weight\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msps_sorted_by_weight\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[0mmin_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Image' object has no attribute 'superpixels'"
     ]
    }
   ],
   "source": [
    "#[SOLUTION]\n",
    "\n",
    "important_superpixels = la.find_important_parts(annotated_image, 4)\n",
    "relations = la.find_spatial_relations(important_superpixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'true_class': 1,\n",
       " 'original_image': array([[[0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         ...,\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ]],\n",
       " \n",
       "        [[0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         ...,\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ]],\n",
       " \n",
       "        [[0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         ...,\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         ...,\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ]],\n",
       " \n",
       "        [[0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         ...,\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ]],\n",
       " \n",
       "        [[0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         ...,\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ],\n",
       "         [0.5019608, 0.       , 0.       ]]], dtype=float32),\n",
       " 'superpixel_mask': array([[ 0,  0,  0, ...,  7,  7,  7],\n",
       "        [ 0,  0,  0, ...,  7,  7,  7],\n",
       "        [ 0,  0,  0, ...,  7,  7,  7],\n",
       "        ...,\n",
       "        [56, 56, 56, ..., 63, 63, 63],\n",
       "        [56, 56, 56, ..., 63, 63, 63],\n",
       "        [56, 56, 56, ..., 63, 63, 63]]),\n",
       " 'superpixels': [<lime_aleph.Superpixel at 0x192f1f6d0>,\n",
       "  <lime_aleph.Superpixel at 0x192d9f070>,\n",
       "  <lime_aleph.Superpixel at 0x192827130>,\n",
       "  <lime_aleph.Superpixel at 0x192ee4340>,\n",
       "  <lime_aleph.Superpixel at 0x192ee8910>,\n",
       "  <lime_aleph.Superpixel at 0x192ee4c70>,\n",
       "  <lime_aleph.Superpixel at 0x10a19e970>,\n",
       "  <lime_aleph.Superpixel at 0x192ee4220>,\n",
       "  <lime_aleph.Superpixel at 0x192823b80>,\n",
       "  <lime_aleph.Superpixel at 0x192d94c40>,\n",
       "  <lime_aleph.Superpixel at 0x192ee4e50>,\n",
       "  <lime_aleph.Superpixel at 0x192d94520>,\n",
       "  <lime_aleph.Superpixel at 0x192d94ac0>,\n",
       "  <lime_aleph.Superpixel at 0x192d94ee0>,\n",
       "  <lime_aleph.Superpixel at 0x192d94220>,\n",
       "  <lime_aleph.Superpixel at 0x192d94310>,\n",
       "  <lime_aleph.Superpixel at 0x192d942e0>,\n",
       "  <lime_aleph.Superpixel at 0x192d943d0>,\n",
       "  <lime_aleph.Superpixel at 0x192d942b0>,\n",
       "  <lime_aleph.Superpixel at 0x192d94c70>,\n",
       "  <lime_aleph.Superpixel at 0x192d94f40>,\n",
       "  <lime_aleph.Superpixel at 0x192d949d0>,\n",
       "  <lime_aleph.Superpixel at 0x192d946a0>,\n",
       "  <lime_aleph.Superpixel at 0x192d949a0>,\n",
       "  <lime_aleph.Superpixel at 0x192d94820>,\n",
       "  <lime_aleph.Superpixel at 0x192d948b0>,\n",
       "  <lime_aleph.Superpixel at 0x192d94730>,\n",
       "  <lime_aleph.Superpixel at 0x192d94850>,\n",
       "  <lime_aleph.Superpixel at 0x192d94d60>,\n",
       "  <lime_aleph.Superpixel at 0x192d94e50>,\n",
       "  <lime_aleph.Superpixel at 0x192d94370>,\n",
       "  <lime_aleph.Superpixel at 0x192d945e0>,\n",
       "  <lime_aleph.Superpixel at 0x192d94160>,\n",
       "  <lime_aleph.Superpixel at 0x192d94490>,\n",
       "  <lime_aleph.Superpixel at 0x192d94940>,\n",
       "  <lime_aleph.Superpixel at 0x192d94be0>,\n",
       "  <lime_aleph.Superpixel at 0x192d94880>,\n",
       "  <lime_aleph.Superpixel at 0x192d94a90>,\n",
       "  <lime_aleph.Superpixel at 0x192e7d7c0>,\n",
       "  <lime_aleph.Superpixel at 0x192d94100>,\n",
       "  <lime_aleph.Superpixel at 0x192d94dc0>,\n",
       "  <lime_aleph.Superpixel at 0x192d945b0>,\n",
       "  <lime_aleph.Superpixel at 0x192d94c10>,\n",
       "  <lime_aleph.Superpixel at 0x192d94b20>,\n",
       "  <lime_aleph.Superpixel at 0x192e7db80>,\n",
       "  <lime_aleph.Superpixel at 0x192d944f0>,\n",
       "  <lime_aleph.Superpixel at 0x192e7dcd0>,\n",
       "  <lime_aleph.Superpixel at 0x192d94430>,\n",
       "  <lime_aleph.Superpixel at 0x192d94f10>,\n",
       "  <lime_aleph.Superpixel at 0x192d94790>,\n",
       "  <lime_aleph.Superpixel at 0x192d947c0>,\n",
       "  <lime_aleph.Superpixel at 0x192f44c40>,\n",
       "  <lime_aleph.Superpixel at 0x192f44a60>,\n",
       "  <lime_aleph.Superpixel at 0x192ddb580>,\n",
       "  <lime_aleph.Superpixel at 0x192f44070>,\n",
       "  <lime_aleph.Superpixel at 0x192ddbf70>,\n",
       "  <lime_aleph.Superpixel at 0x192f02100>,\n",
       "  <lime_aleph.Superpixel at 0x192f44ca0>,\n",
       "  <lime_aleph.Superpixel at 0x192f02b80>,\n",
       "  <lime_aleph.Superpixel at 0x192f44be0>,\n",
       "  <lime_aleph.Superpixel at 0x192f028e0>,\n",
       "  <lime_aleph.Superpixel at 0x192f44160>,\n",
       "  <lime_aleph.Superpixel at 0x192f44f10>,\n",
       "  <lime_aleph.Superpixel at 0x192f02b50>]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'important_superpixels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-47a37101b1b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimportant_superpixels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'important_superpixels' is not defined"
     ]
    }
   ],
   "source": [
    "important_superpixels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 44,\n",
       " 'name': 'sp_44',\n",
       " 'color': 'darkturquoise',\n",
       " 'size': 16,\n",
       " 'lime_weight': 0.1147492499928618,\n",
       " 'x_coord': 17.5,\n",
       " 'y_coord': 21.5}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(important_superpixels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 60,\n",
       " 'name': 'sp_60',\n",
       " 'color': 'mediumblue',\n",
       " 'size': 16,\n",
       " 'lime_weight': 0.10612414946491816,\n",
       " 'x_coord': 17.5,\n",
       " 'y_coord': 29.5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(important_superpixels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 52,\n",
       " 'name': 'sp_52',\n",
       " 'color': 'lime',\n",
       " 'size': 16,\n",
       " 'lime_weight': 0.09594455199558823,\n",
       " 'x_coord': 17.5,\n",
       " 'y_coord': 25.5}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(important_superpixels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Liste, welche von der Funktion zum Finden von Relationen zurückgegeben wurde, beinhaltet Objekte vom Typ __Relation__. Hier geben wir nun beispielhaft die Informationen der ersten Relation aus. Natürlich müssen Sie den Namen der Liste an Ihre Implementation anpassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: bottom_of\n",
      "Start: 60\n",
      "To: 44\n"
     ]
    }
   ],
   "source": [
    "print(\"Name:\", relations[0].name)\n",
    "print(\"Start:\", relations[0].start)\n",
    "print(\"To:\", relations[0].to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 --bottom_of--> 44\n",
      "52 --under--> 44\n",
      "52 --bottom_of--> 44\n",
      "48 --left_of--> 44\n",
      "44 --top_of--> 60\n",
      "52 --on--> 60\n",
      "52 --top_of--> 60\n",
      "48 --left_of--> 60\n",
      "44 --on--> 52\n",
      "44 --top_of--> 52\n",
      "60 --under--> 52\n",
      "60 --bottom_of--> 52\n",
      "48 --left_of--> 52\n",
      "44 --right_of--> 48\n",
      "60 --right_of--> 48\n",
      "52 --right_of--> 48\n"
     ]
    }
   ],
   "source": [
    "for idx in relations:\n",
    "    print(idx.start, \"--\"+idx.name+\"-->\", idx.to) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Name beschreibt das Prädikat der räumlichen Relation. Die weiteren Informationen beschreiben die Indices der Start- und Zielelemente der Relation innerhalb des Bildes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wollen wir das perturbierte Datenset für LIME-Aleph generieren lassen. Benutzen Sie hierzu die Funktion __perturb_instance__ mit den erforderlichen Parametern. Lassen Sie sich auch ausgeben, wie viele Instanzen im neuen Datenset sind (Es wird eine Liste mit Instanzen zurückgegeben)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of perturbed instances: 17\n"
     ]
    }
   ],
   "source": [
    "#[SOLUTION]\n",
    "perturbed_dataset = la.perturb_instance(annotated_image, relations, model, T)\n",
    "print(\"Number of perturbed instances:\", len(perturbed_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 44, 'name': 'sp_44', 'color': 'darkturquoise', 'size': 16, 'lime_weight': 0.1147492499928618, 'x_coord': 17.5, 'y_coord': 21.5}\n",
      "{'id': 60, 'name': 'sp_60', 'color': 'mediumblue', 'size': 16, 'lime_weight': 0.10612414946491816, 'x_coord': 17.5, 'y_coord': 29.5}\n",
      "{'id': 52, 'name': 'sp_52', 'color': 'lime', 'size': 16, 'lime_weight': 0.09594455199558823, 'x_coord': 17.5, 'y_coord': 25.5}\n",
      "{'id': 48, 'name': 'sp_48', 'color': 'maroon', 'size': 16, 'lime_weight': -0.04471325524619362, 'x_coord': 1.5, 'y_coord': 25.5}\n",
      "{'id': 10, 'name': 'sp_10', 'color': 'maroon', 'size': 16, 'lime_weight': -0.042861667219122955, 'x_coord': 9.5, 'y_coord': 5.5}\n",
      "{'id': 17, 'name': 'sp_17', 'color': 'maroon', 'size': 16, 'lime_weight': -0.040696741842656266, 'x_coord': 5.5, 'y_coord': 9.5}\n",
      "{'id': 53, 'name': 'sp_53', 'color': 'maroon', 'size': 16, 'lime_weight': -0.03873590512069972, 'x_coord': 21.5, 'y_coord': 25.5}\n",
      "{'id': 41, 'name': 'sp_41', 'color': 'maroon', 'size': 16, 'lime_weight': -0.03511165823358521, 'x_coord': 5.5, 'y_coord': 21.5}\n",
      "{'id': 42, 'name': 'sp_42', 'color': 'maroon', 'size': 16, 'lime_weight': -0.03406053637765858, 'x_coord': 9.5, 'y_coord': 21.5}\n",
      "{'id': 50, 'name': 'sp_50', 'color': 'maroon', 'size': 16, 'lime_weight': -0.03400254754601082, 'x_coord': 9.5, 'y_coord': 25.5}\n",
      "{'id': 45, 'name': 'sp_45', 'color': 'maroon', 'size': 16, 'lime_weight': -0.030626829520449806, 'x_coord': 21.5, 'y_coord': 21.5}\n",
      "{'id': 34, 'name': 'sp_34', 'color': 'maroon', 'size': 16, 'lime_weight': -0.029723969870578664, 'x_coord': 9.5, 'y_coord': 17.5}\n",
      "{'id': 54, 'name': 'sp_54', 'color': 'maroon', 'size': 16, 'lime_weight': -0.029345078687959124, 'x_coord': 25.5, 'y_coord': 25.5}\n",
      "{'id': 40, 'name': 'sp_40', 'color': 'maroon', 'size': 16, 'lime_weight': -0.028135710391808816, 'x_coord': 1.5, 'y_coord': 21.5}\n",
      "{'id': 18, 'name': 'sp_18', 'color': 'maroon', 'size': 16, 'lime_weight': -0.027948492920774188, 'x_coord': 9.5, 'y_coord': 9.5}\n",
      "{'id': 57, 'name': 'sp_57', 'color': 'maroon', 'size': 16, 'lime_weight': -0.027840963429139852, 'x_coord': 5.5, 'y_coord': 29.5}\n",
      "{'id': 14, 'name': 'sp_14', 'color': 'maroon', 'size': 16, 'lime_weight': -0.02731158867698219, 'x_coord': 25.5, 'y_coord': 5.5}\n",
      "{'id': 26, 'name': 'sp_26', 'color': 'maroon', 'size': 16, 'lime_weight': -0.026444598137094606, 'x_coord': 9.5, 'y_coord': 13.5}\n",
      "{'id': 29, 'name': 'sp_29', 'color': 'maroon', 'size': 16, 'lime_weight': -0.023221443456149727, 'x_coord': 21.5, 'y_coord': 13.5}\n",
      "{'id': 19, 'name': 'sp_19', 'color': 'maroon', 'size': 16, 'lime_weight': -0.022857631716684274, 'x_coord': 13.5, 'y_coord': 9.5}\n",
      "{'id': 24, 'name': 'sp_24', 'color': 'maroon', 'size': 16, 'lime_weight': -0.022384147722965424, 'x_coord': 1.5, 'y_coord': 13.5}\n",
      "{'id': 21, 'name': 'sp_21', 'color': 'maroon', 'size': 16, 'lime_weight': -0.02079116619692924, 'x_coord': 21.5, 'y_coord': 9.5}\n",
      "{'id': 32, 'name': 'sp_32', 'color': 'maroon', 'size': 16, 'lime_weight': -0.020558591506413596, 'x_coord': 1.5, 'y_coord': 17.5}\n",
      "{'id': 51, 'name': 'sp_51', 'color': 'maroon', 'size': 16, 'lime_weight': -0.01937013494725799, 'x_coord': 13.5, 'y_coord': 25.5}\n",
      "{'id': 13, 'name': 'sp_13', 'color': 'maroon', 'size': 16, 'lime_weight': -0.019003774909456757, 'x_coord': 21.5, 'y_coord': 5.5}\n",
      "{'id': 25, 'name': 'sp_25', 'color': 'maroon', 'size': 16, 'lime_weight': -0.017606223451654072, 'x_coord': 5.5, 'y_coord': 13.5}\n",
      "{'id': 16, 'name': 'sp_16', 'color': 'maroon', 'size': 16, 'lime_weight': -0.017155316581784794, 'x_coord': 1.5, 'y_coord': 9.5}\n",
      "{'id': 20, 'name': 'sp_20', 'color': 'maroon', 'size': 16, 'lime_weight': -0.016189323753193072, 'x_coord': 17.5, 'y_coord': 9.5}\n",
      "{'id': 3, 'name': 'sp_3', 'color': 'maroon', 'size': 16, 'lime_weight': -0.015508233251422242, 'x_coord': 13.5, 'y_coord': 1.5}\n",
      "{'id': 61, 'name': 'sp_61', 'color': 'maroon', 'size': 16, 'lime_weight': -0.014289296743052664, 'x_coord': 21.5, 'y_coord': 29.5}\n",
      "{'id': 5, 'name': 'sp_5', 'color': 'maroon', 'size': 16, 'lime_weight': -0.013702918445720238, 'x_coord': 21.5, 'y_coord': 1.5}\n",
      "{'id': 35, 'name': 'sp_35', 'color': 'maroon', 'size': 16, 'lime_weight': -0.013107002559109298, 'x_coord': 13.5, 'y_coord': 17.5}\n",
      "{'id': 22, 'name': 'sp_22', 'color': 'maroon', 'size': 16, 'lime_weight': -0.012777323425329567, 'x_coord': 25.5, 'y_coord': 9.5}\n",
      "{'id': 38, 'name': 'sp_38', 'color': 'maroon', 'size': 16, 'lime_weight': -0.012703192378807699, 'x_coord': 25.5, 'y_coord': 17.5}\n",
      "{'id': 63, 'name': 'sp_63', 'color': 'maroon', 'size': 16, 'lime_weight': -0.012279784409175576, 'x_coord': 29.5, 'y_coord': 29.5}\n",
      "{'id': 59, 'name': 'sp_59', 'color': 'maroon', 'size': 16, 'lime_weight': -0.01182689300423197, 'x_coord': 13.5, 'y_coord': 29.5}\n",
      "{'id': 12, 'name': 'sp_12', 'color': 'maroon', 'size': 16, 'lime_weight': -0.01155264636862703, 'x_coord': 17.5, 'y_coord': 5.5}\n",
      "{'id': 43, 'name': 'sp_43', 'color': 'maroon', 'size': 16, 'lime_weight': -0.01129346976738766, 'x_coord': 13.5, 'y_coord': 21.5}\n",
      "{'id': 56, 'name': 'sp_56', 'color': 'maroon', 'size': 16, 'lime_weight': -0.011291315590738116, 'x_coord': 1.5, 'y_coord': 29.5}\n",
      "{'id': 0, 'name': 'sp_0', 'color': 'maroon', 'size': 16, 'lime_weight': -0.01121289459764548, 'x_coord': 1.5, 'y_coord': 1.5}\n",
      "{'id': 62, 'name': 'sp_62', 'color': 'maroon', 'size': 16, 'lime_weight': 0.011170610792208609, 'x_coord': 25.5, 'y_coord': 29.5}\n",
      "{'id': 36, 'name': 'sp_36', 'color': 'maroon', 'size': 16, 'lime_weight': -0.01094104191082158, 'x_coord': 17.5, 'y_coord': 17.5}\n",
      "{'id': 58, 'name': 'sp_58', 'color': 'maroon', 'size': 16, 'lime_weight': -0.010566066289578761, 'x_coord': 9.5, 'y_coord': 29.5}\n",
      "{'id': 9, 'name': 'sp_9', 'color': 'maroon', 'size': 16, 'lime_weight': 0.010385461644600212, 'x_coord': 5.5, 'y_coord': 5.5}\n",
      "{'id': 39, 'name': 'sp_39', 'color': 'maroon', 'size': 16, 'lime_weight': -0.010300165401298383, 'x_coord': 29.5, 'y_coord': 17.5}\n",
      "{'id': 31, 'name': 'sp_31', 'color': 'maroon', 'size': 16, 'lime_weight': -0.01024373122376159, 'x_coord': 29.5, 'y_coord': 13.5}\n",
      "{'id': 33, 'name': 'sp_33', 'color': 'maroon', 'size': 16, 'lime_weight': -0.009758286010069091, 'x_coord': 5.5, 'y_coord': 17.5}\n",
      "{'id': 11, 'name': 'sp_11', 'color': 'maroon', 'size': 16, 'lime_weight': 0.009357377924471446, 'x_coord': 13.5, 'y_coord': 5.5}\n",
      "{'id': 46, 'name': 'sp_46', 'color': 'maroon', 'size': 16, 'lime_weight': -0.008102240743687579, 'x_coord': 25.5, 'y_coord': 21.5}\n",
      "{'id': 47, 'name': 'sp_47', 'color': 'maroon', 'size': 16, 'lime_weight': -0.007347385071166499, 'x_coord': 29.5, 'y_coord': 21.5}\n",
      "{'id': 6, 'name': 'sp_6', 'color': 'maroon', 'size': 16, 'lime_weight': 0.007228561857237114, 'x_coord': 25.5, 'y_coord': 1.5}\n",
      "{'id': 30, 'name': 'sp_30', 'color': 'maroon', 'size': 16, 'lime_weight': -0.006434159396752457, 'x_coord': 25.5, 'y_coord': 13.5}\n",
      "{'id': 7, 'name': 'sp_7', 'color': 'maroon', 'size': 16, 'lime_weight': -0.006393849279443414, 'x_coord': 29.5, 'y_coord': 1.5}\n",
      "{'id': 1, 'name': 'sp_1', 'color': 'maroon', 'size': 16, 'lime_weight': -0.006198162412613521, 'x_coord': 5.5, 'y_coord': 1.5}\n",
      "{'id': 37, 'name': 'sp_37', 'color': 'maroon', 'size': 16, 'lime_weight': 0.005931856488638536, 'x_coord': 21.5, 'y_coord': 17.5}\n",
      "{'id': 8, 'name': 'sp_8', 'color': 'maroon', 'size': 16, 'lime_weight': 0.005629368095547148, 'x_coord': 1.5, 'y_coord': 5.5}\n",
      "{'id': 2, 'name': 'sp_2', 'color': 'maroon', 'size': 16, 'lime_weight': 0.005258256684988363, 'x_coord': 9.5, 'y_coord': 1.5}\n",
      "{'id': 49, 'name': 'sp_49', 'color': 'maroon', 'size': 16, 'lime_weight': -0.002874932315596661, 'x_coord': 5.5, 'y_coord': 25.5}\n",
      "{'id': 23, 'name': 'sp_23', 'color': 'maroon', 'size': 16, 'lime_weight': -0.0025444739263799825, 'x_coord': 29.5, 'y_coord': 9.5}\n",
      "{'id': 15, 'name': 'sp_15', 'color': 'maroon', 'size': 16, 'lime_weight': -0.0007767081777320581, 'x_coord': 29.5, 'y_coord': 5.5}\n",
      "{'id': 28, 'name': 'sp_28', 'color': 'maroon', 'size': 16, 'lime_weight': -0.0007561330606734118, 'x_coord': 17.5, 'y_coord': 13.5}\n",
      "{'id': 55, 'name': 'sp_55', 'color': 'maroon', 'size': 16, 'lime_weight': 0.0005562771451759953, 'x_coord': 29.5, 'y_coord': 25.5}\n",
      "{'id': 27, 'name': 'sp_27', 'color': 'maroon', 'size': 16, 'lime_weight': 0.00029049233318270446, 'x_coord': 13.5, 'y_coord': 13.5}\n",
      "{'id': 4, 'name': 'sp_4', 'color': 'maroon', 'size': 16, 'lime_weight': 0.0002542542737326466, 'x_coord': 17.5, 'y_coord': 1.5}\n"
     ]
    }
   ],
   "source": [
    "for idx in annotated_image.superpixels:\n",
    "    print(vars(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ILP-Framework Aleph benötigt mehrere Hilfsdateien, die mit der Funktion __write_aleph_files__ erzeugt werden. Rufen Sie diese Funktion auf. Es sollen alle räumlichen Relationen verwendet werden! Zur Verfügung stehen folgende Relationen: *left_of*, *right_of*, *top_of*, *bottom_of*, *on*, *under*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing the input files for Aleph...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#[SOLUTION]\n",
    "used_relations = None # 'None' if you want to allow all relations, otherwise list with following possibilities: [\"left_of\", \"right_of\", \"top_of\", \"bottom_of\", \"on\", \"under\"]\n",
    "la.write_aleph_files(annotated_image, perturbed_dataset, used_relations, OUTPUT_DIR, NOISE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schlussendlich muss nun der Induktionsprozess von Aleph angestoßen werden. Dieser Schritt (mit der Funktion __run_aleph__) gibt auch die gefundene Erklärung aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{}]\n",
      "[{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]\n",
      "[{}]\n",
      "[{}]\n",
      "[{}]\n",
      "The explanation was saved to '../output/explanation.txt'\n"
     ]
    }
   ],
   "source": [
    "#[SOLUTION]\n",
    "la.run_aleph(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Erklärung in Form von Regeln kann nun im angegebenen Ordner in der Datei *explanation.txt* gefunden und interpretiert werden. Wir lesen nun diese Datei aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_class(A) :-\n",
      "   contains(B,A), has_color(B,mediumblue), contains(C,A), has_color(C,lime), \n",
      "   top_of_in_ex(C,B,A).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(OUTPUT_DIR + \"explanation.txt\", 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation \n",
    "...\n",
    "\n",
    "\n",
    "true_class(A) :-\n",
    "   contains(B,A), has_color(B,mediumblue), contains(C,A), has_color(C,lime), \n",
    "   top_of_in_ex(C,B,A).\n",
    "\n",
    "## Interpretierte Regel\n",
    "\n",
    "true_class(Turm) :-\n",
    "   contains(Blau,Turm), has_color(Blau,mediumblue), contains(Grün,Turm), has_color(Grün,lime), \n",
    "   top_of_in_ex(Grün,Blau,Turm).\n",
    "\n",
    "übersetzt in Satz\n",
    "Turm ist wahr wenn gilt: Der blaue Klotz gehört zu einem Turm, ... \n",
    "\n",
    "[Bild]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
